# ARCHITECTURE FINALE - MECAPY (Sans hypothÃ¨se de limites)

## ğŸ¯ PROBLÃ‰MATIQUE

### Contraintes confirmÃ©es
- âœ… DÃ©veloppeur solo (pas de gestion infra complexe)
- âœ… Provider franÃ§ais/europÃ©en
- âš ï¸ **Limite probable : 1000 containers/functions chez Scaleway**
- âœ… Besoin : Multi-utilisateurs, multi-calculs simultanÃ©s
- âœ… Calculs courts (secondes) ET longs (heures) possibles

---

## ğŸš€ SOLUTION : Architecture MutualisÃ©e (1 Container = N Calculs)

### Concept clÃ© : **Worker Pool au lieu de 1 container par calcul**

```
âŒ MAUVAISE approche (hit la limite):
1 calcul utilisateur = 1 Serverless Container dÃ©ployÃ©
â†’ 1000 utilisateurs Ã— 1 calcul = LIMITE ATTEINTE

âœ… BONNE approche (scalable):
1 Serverless Container = Worker qui traite N calculs en sÃ©quence
â†’ 10 workers Ã— 100 calculs chacun = 1000 calculs sans problÃ¨me
```

---

## ğŸ—ï¸ ARCHITECTURE PROPOSÃ‰E : Worker Pool Serverless

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  UTILISATEURS (N)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI (Clever Cloud)                      â”‚
â”‚         - Auth Keycloak                             â”‚
â”‚         - API CRUD tasks/workflows                  â”‚
â”‚         - Enqueue jobs dans Redis                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL      â”‚   â”‚  Redis Queue   â”‚
â”‚  (Scaleway)      â”‚   â”‚  (Scaleway)    â”‚
â”‚  - Tasks meta    â”‚   â”‚  - Job queue   â”‚
â”‚  - Users/orgs    â”‚   â”‚  - Results     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                        â”‚
        â”‚   WORKER POOL (3-10 containers)        â”‚
        â”‚                                        â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
  â”‚ Worker 1  â”‚  â”‚ Worker 2 â”‚  â”‚ Worker N â”‚     â”‚
  â”‚ (Containerâ”‚  â”‚ (Containerâ”‚  â”‚ (Containerâ”‚     â”‚
  â”‚ Serverlessâ”‚  â”‚ Serverlessâ”‚  â”‚ Serverlessâ”‚     â”‚
  â”‚           â”‚  â”‚           â”‚  â”‚           â”‚     â”‚
  â”‚ Poll Redisâ”‚  â”‚ Poll Redisâ”‚  â”‚ Poll Redisâ”‚     â”‚
  â”‚ Execute   â”‚  â”‚ Execute   â”‚  â”‚ Execute   â”‚     â”‚
  â”‚ Push S3   â”‚  â”‚ Push S3   â”‚  â”‚ Push S3   â”‚     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Object Storage   â”‚
                    â”‚ (Scaleway S3)    â”‚
                    â”‚ - Inputs/Outputs â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ COMPOSANTS DÃ‰TAILLÃ‰S

### **1. API FastAPI (Clever Cloud)**

**RÃ´le** : Point d'entrÃ©e unique, gestion mÃ©tadonnÃ©es

```python
# api/routes/tasks.py
from fastapi import APIRouter
import redis

router = APIRouter()
redis_client = redis.from_url(os.getenv("REDIS_URL"))

@router.post("/tasks")
async def create_task(task: TaskCreate, user: User):
    """CrÃ©er une tÃ¢che et l'enqueue"""

    # 1. Sauvegarder metadata en DB
    task_db = await db.tasks.create({
        "id": uuid.uuid4(),
        "user_id": user.id,
        "name": task.name,
        "code": task.code,
        "status": "queued",
        "created_at": datetime.utcnow()
    })

    # 2. Upload inputs vers S3
    s3_key = f"inputs/{task_db.id}.json"
    await s3.upload(s3_key, task.inputs)

    # 3. Enqueue job dans Redis
    redis_client.rpush("mecapy:jobs", json.dumps({
        "task_id": str(task_db.id),
        "user_id": str(user.id),
        "code_s3_key": f"code/{task_db.id}.py",
        "inputs_s3_key": s3_key,
        "priority": task.priority or 5,
        "timeout": task.timeout or 300  # 5min default
    }))

    return {"task_id": task_db.id, "status": "queued"}


@router.get("/tasks/{task_id}")
async def get_task_status(task_id: str):
    """RÃ©cupÃ©rer le statut d'une tÃ¢che"""
    task = await db.tasks.get(task_id)

    # Si completed, rÃ©cupÃ©rer rÃ©sultats depuis Redis ou S3
    if task.status == "completed":
        result = redis_client.get(f"result:{task_id}")
        if not result:
            # Fallback S3 si expirÃ© de Redis
            result = await s3.download(f"results/{task_id}.json")

    return {
        "task_id": task_id,
        "status": task.status,
        "result": result if task.status == "completed" else None,
        "error": task.error_message if task.status == "failed" else None
    }
```

---

### **2. Worker Pool (Serverless Containers)**

**Architecture** : 3-10 containers permanents qui **consomment** la queue Redis

#### **Dockerfile Worker**
```dockerfile
FROM python:3.12-slim

# Installer dÃ©pendances scientifiques
RUN pip install \
    numpy \
    scipy \
    pandas \
    matplotlib \
    redis \
    boto3 \
    RestrictedPython

COPY worker/ /app/
WORKDIR /app

# Worker daemon qui poll Redis en continu
CMD ["python", "worker.py"]
```

#### **Code Worker**
```python
# worker/worker.py
import redis
import boto3
import json
import time
from sandbox import execute_user_code

# Config
REDIS_URL = os.getenv("REDIS_URL")
S3_BUCKET = os.getenv("S3_BUCKET")

redis_client = redis.from_url(REDIS_URL)
s3_client = boto3.client('s3')

def process_job(job_data: dict):
    """Traiter un job de calcul"""

    task_id = job_data['task_id']

    try:
        # 1. Update status = running
        redis_client.hset(f"task:{task_id}", "status", "running")
        redis_client.hset(f"task:{task_id}", "started_at", time.time())

        # 2. Download code et inputs depuis S3
        code = s3_client.get_object(
            Bucket=S3_BUCKET,
            Key=job_data['code_s3_key']
        )['Body'].read().decode()

        inputs = json.loads(
            s3_client.get_object(
                Bucket=S3_BUCKET,
                Key=job_data['inputs_s3_key']
            )['Body'].read()
        )

        # 3. ExÃ©cuter code utilisateur (sandboxed)
        result = execute_user_code(
            code=code,
            inputs=inputs,
            timeout=job_data.get('timeout', 300)
        )

        # 4. Upload rÃ©sultat vers S3
        s3_client.put_object(
            Bucket=S3_BUCKET,
            Key=f"results/{task_id}.json",
            Body=json.dumps(result)
        )

        # 5. Cache rÃ©sultat dans Redis (TTL 1h)
        redis_client.setex(
            f"result:{task_id}",
            3600,  # 1h expiration
            json.dumps(result)
        )

        # 6. Update status = completed
        redis_client.hset(f"task:{task_id}", "status", "completed")
        redis_client.hset(f"task:{task_id}", "completed_at", time.time())

    except Exception as e:
        # Gestion erreur
        redis_client.hset(f"task:{task_id}", "status", "failed")
        redis_client.hset(f"task:{task_id}", "error", str(e))


def main():
    """Worker daemon - Poll Redis en continu"""

    print(f"ğŸš€ Worker started - polling Redis queue...")

    while True:
        try:
            # Blocking pop (attend jusqu'Ã  5s)
            job = redis_client.blpop("mecapy:jobs", timeout=5)

            if job:
                job_data = json.loads(job[1])
                print(f"ğŸ“‹ Processing task {job_data['task_id']}")

                process_job(job_data)

                print(f"âœ… Task {job_data['task_id']} completed")

        except Exception as e:
            print(f"âŒ Worker error: {e}")
            time.sleep(1)  # Ã‰viter boucle rapide en cas d'erreur

if __name__ == "__main__":
    main()
```

---

### **3. DÃ©ploiement Worker Pool**

**Option A : Scaleway Serverless Containers (si limites acceptables)**

```bash
# Build image
docker build -t mecapy-worker:v1 ./worker
docker push registry.scaleway.com/mecapy/worker:v1

# DÃ©ployer 5 workers identiques
for i in {1..5}; do
  scw container container create \
    --name mecapy-worker-$i \
    --namespace-id <namespace-id> \
    --registry-image mecapy/worker:v1 \
    --min-scale 1 \
    --max-scale 1 \
    --memory-limit 2048 \
    --cpu-limit 1000 \
    --env REDIS_URL=$REDIS_URL \
    --env S3_BUCKET=$S3_BUCKET
done
```

**Avantages** :
- âœ… 5-10 containers = trÃ¨s loin de la limite 1000
- âœ… Chaque worker traite des centaines de calculs
- âœ… Auto-restart si crash
- âœ… CoÃ»t fixe prÃ©visible

**Option B : Scaleway Instances (VMs lÃ©gÃ¨res) - SI containers limitÃ©s**

```bash
# DÃ©ployer 3 VMs DEV1-S (2 vCPU, 2GB RAM)
scw instance server create \
  name=mecapy-worker-1 \
  type=DEV1-S \
  image=ubuntu_jammy \
  cloud-init=worker-init.yaml

# cloud-init.yaml
#cloud-config
runcmd:
  - docker pull registry.scaleway.com/mecapy/worker:v1
  - docker run -d --restart=always \
      -e REDIS_URL=$REDIS_URL \
      -e S3_BUCKET=$S3_BUCKET \
      registry.scaleway.com/mecapy/worker:v1
```

**CoÃ»t** : 3x DEV1-S = ~â‚¬18/mois (vs â‚¬50/mois pour containers serverless)

---

## ğŸ“Š COMPARAISON DES OPTIONS BACKEND

| Option | Gestion infra | CoÃ»t | Limite | Recommandation |
|--------|---------------|------|--------|----------------|
| **Serverless Containers** (worker pool) | âš¡ Minimal | â‚¬30-50/mois | âœ… Seulement 5-10 containers | âœ…âœ… **IdÃ©al** |
| **Instances VMs** (worker pool) | ğŸŸ¡ Moyenne | â‚¬18-30/mois | âœ… IllimitÃ© | âœ… Backup si containers limitÃ©s |
| **Kubernetes** | ğŸ”´ Ã‰levÃ©e | â‚¬50+/mois | âœ… IllimitÃ© | âŒ Trop complexe solo |
| **1 Container par calcul** | âš¡ Zero | â‚¬10-20/mois | âŒ HIT limite 1000 | âŒ Non scalable |

---

## ğŸ’° COÃ›TS DÃ‰TAILLÃ‰S

### **Architecture Worker Pool (Serverless Containers)**

| Service | Configuration | CoÃ»t mensuel |
|---------|---------------|--------------|
| **API FastAPI** | Clever Cloud Nano | â‚¬7-10/mois |
| **PostgreSQL** | Scaleway DB 1GB | â‚¬18/mois |
| **Redis** | Scaleway DB 512MB | â‚¬15/mois |
| **Object Storage** | Scaleway S3 (50GB) | â‚¬1/mois |
| **5x Workers** | Serverless Containers (min=1, max=1) | â‚¬30-40/mois |
| **Registry** | Container Registry | Gratuit |
| **Total** | | **â‚¬70-85/mois** |

**CapacitÃ©** : 1000-5000 calculs/jour selon durÃ©e moyenne

### **Architecture Worker Pool (VMs)**

| Service | Configuration | CoÃ»t mensuel |
|---------|---------------|--------------|
| **API + DB + Redis** | Identique ci-dessus | â‚¬40/mois |
| **3x Instances** | DEV1-S (2vCPU, 2GB) | â‚¬18/mois |
| **Object Storage** | Scaleway S3 | â‚¬1/mois |
| **Total** | | **â‚¬60-65/mois** |

**CapacitÃ©** : Identique (mÃªme puissance calcul)

---

## ğŸ”¥ GESTION DES CALCULS LONGS (> 10min)

### **StratÃ©gie : Router automatique**

```python
# api/services/task_router.py
async def route_task(task: Task) -> str:
    """Router selon estimation de durÃ©e"""

    estimated_duration = estimate_duration(task)

    if estimated_duration < 600:  # < 10min
        # Enqueue dans Redis normale
        redis_client.rpush("mecapy:jobs", serialize(task))
        return "worker_pool"

    else:
        # Lancer instance dÃ©diÃ©e on-demand
        instance_id = await launch_dedicated_instance(task)
        return f"dedicated_instance:{instance_id}"


async def launch_dedicated_instance(task: Task) -> str:
    """Lancer une VM on-demand pour calcul long"""

    # CrÃ©er instance Scaleway avec cloud-init
    instance = await scw_api.create_instance(
        name=f"compute-{task.id}",
        type="DEV1-M",  # ou GPU1-S si besoin GPU
        image="docker_ubuntu",
        cloud_init=f"""
        #!/bin/bash
        # Download code et inputs
        aws s3 cp s3://{S3_BUCKET}/code/{task.id}.py /tmp/code.py
        aws s3 cp s3://{S3_BUCKET}/inputs/{task.id}.json /tmp/inputs.json

        # Execute
        python3 /tmp/code.py < /tmp/inputs.json > /tmp/output.json

        # Upload rÃ©sultats
        aws s3 cp /tmp/output.json s3://{S3_BUCKET}/results/{task.id}.json

        # Update status via API
        curl -X PATCH https://api.mecapy.com/tasks/{task.id} \
          -d '{{"status": "completed"}}'

        # Auto-destroy instance
        scw instance server delete {instance.id}
        """
    )

    return instance.id
```

**CoÃ»t calculs longs** :
- DEV1-M : â‚¬0.024/h â†’ 1h calcul = â‚¬0.024
- GPU1-S : â‚¬0.50/h â†’ 2h calcul = â‚¬1.00

---

## âš¡ SCALING STRATÃ‰GIE

### **Phase 1 : MVP (0-1000 calculs/jour)**
```
3 Workers (Serverless Containers ou VMs)
CoÃ»t : â‚¬60-70/mois
```

### **Phase 2 : Growth (1000-5000 calculs/jour)**
```
5-8 Workers
CoÃ»t : â‚¬80-100/mois
```

### **Phase 3 : Scale (5000-20 000 calculs/jour)**
```
10-15 Workers + Auto-scaling Redis-based
CoÃ»t : â‚¬120-150/mois
```

### **Auto-scaling Worker Pool** (si VMs)
```python
# monitoring/autoscaler.py
import redis
import time

def autoscale_workers():
    """Scale workers selon queue depth"""

    queue_depth = redis_client.llen("mecapy:jobs")
    current_workers = get_active_workers()

    if queue_depth > 100 and current_workers < 10:
        # Scale up
        spawn_worker()

    elif queue_depth < 10 and current_workers > 3:
        # Scale down
        kill_idle_worker()

# Run every 30s
while True:
    autoscale_workers()
    time.sleep(30)
```

---

## âœ… AVANTAGES ARCHITECTURE FINALE

### **Pour dÃ©veloppeur solo** :
1. âœ… **Gestion infra minimale** : API + 5 workers = c'est tout
2. âœ… **Pas de limite artificielle** : Worker pool traite N calculs
3. âœ… **CoÃ»t prÃ©visible** : â‚¬60-85/mois fixe
4. âœ… **Debugging facile** : Logs centralisÃ©s Redis/S3
5. âœ… **Ã‰volutif** : Ajouter workers = 1 commande

### **Pour utilisateurs** :
1. âœ… **Latence basse** : Workers warm (pas de cold start)
2. âœ… **Queue visible** : Position dans la file d'attente
3. âœ… **Isolation** : Sandbox Python par calcul
4. âœ… **RÃ©sultats persistants** : S3 + cache Redis

### **ScalabilitÃ©** :
- **1000 calculs/jour** : 3 workers suffisent
- **10 000 calculs/jour** : 10 workers suffisent
- **100 000 calculs/jour** : 50 workers + K8s Ã  considÃ©rer

---

## ğŸš€ PLAN DE MISE EN Å’UVRE (4 SEMAINES)

### **Semaine 1 : Infrastructure base**
```bash
# 1. Provisionner services managÃ©s
scw rdb instance create name=mecapy-db engine=postgresql-15
scw redis cluster create name=mecapy-redis

# 2. CrÃ©er bucket S3
scw object bucket create mecapy-storage

# 3. DÃ©ployer API FastAPI sur Clever Cloud
clever create --type python mecapy-api
```

### **Semaine 2 : Worker Pool**
```bash
# 1. Build image worker
docker build -t mecapy-worker:v1 ./worker

# 2. Push vers registry
docker push registry.scaleway.com/mecapy/worker:v1

# 3. DÃ©ployer 3 workers (Serverless Containers OU VMs)
./scripts/deploy_workers.sh 3
```

### **Semaine 3 : API Routes + Tests**
```python
# ImplÃ©menter routes
POST /tasks              # Create task
GET  /tasks/{id}         # Get status
GET  /tasks/{id}/result  # Get result

# Tests end-to-end
pytest tests/test_worker_pool.py
```

### **Semaine 4 : Monitoring + Production**
```bash
# Setup monitoring
- Grafana dashboard (queue depth, worker CPU)
- Alerting (Redis down, workers crashed)

# Go live
clever deploy
```

---

## ğŸ“Š TABLEAU COMPARATIF FINAL

| CritÃ¨re | Worker Pool Serverless | Worker Pool VMs | K8s + Celery |
|---------|------------------------|-----------------|--------------|
| **Gestion infra** | âš¡ Minimal | ğŸŸ¡ Moyenne | ğŸ”´ Ã‰levÃ©e |
| **CoÃ»t base** | â‚¬70/mois | â‚¬60/mois | â‚¬90/mois |
| **CoÃ»t scale** | LinÃ©aire | LinÃ©aire | LinÃ©aire |
| **Limite containers** | âœ… 5-10 seulement | âœ… IllimitÃ© | âœ… IllimitÃ© |
| **ComplexitÃ©** | ğŸŸ¢ Simple | ğŸŸ¢ Simple | ğŸ”´ Complexe |
| **Latence** | ~50ms | ~50ms | ~50ms |
| **Auto-scaling** | ğŸŸ¡ Manuel | ğŸŸ¡ Script Python | âœ… Natif |
| **RecommandÃ© solo** | âœ…âœ…âœ… | âœ…âœ… | âŒ |

---

## ğŸ¯ RECOMMANDATION FINALE

### **â­ CHOIX #1 : Worker Pool Serverless Containers**
```
API FastAPI + 5-10 Workers Serverless Containers + Redis + S3
CoÃ»t : â‚¬70-85/mois
Maintenance : ~2h/mois
```

**Pourquoi** :
- âœ… Simple Ã  dÃ©ployer et maintenir
- âœ… Auto-restart des workers si crash
- âœ… Pas de gestion VMs
- âœ… TrÃ¨s loin de la limite 1000

### **â­ CHOIX #2 (fallback) : Worker Pool VMs**
```
API FastAPI + 3-5 VMs workers + Redis + S3
CoÃ»t : â‚¬60-70/mois
Maintenance : ~3h/mois
```

**Pourquoi** :
- âœ… Moins cher (â‚¬10/mois Ã©conomie)
- âœ… Pas de limite containers
- ğŸŸ¡ Gestion SSH + updates

### **âŒ NE PAS FAIRE : 1 Container par calcul**
â†’ Hit la limite 1000 rapidement

---

**âœ… VERDICT : Worker Pool = Architecture idÃ©ale mÃªme avec limite 1000**

**Document gÃ©nÃ©rÃ© le** : 2025-09-30
**Version** : 3.0 - Architecture finale rÃ©aliste