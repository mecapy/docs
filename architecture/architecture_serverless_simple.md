# ARCHITECTURE SERVERLESS SIMPLIFIÃ‰E - MECAPY

## ğŸ¯ OBJECTIF : ZÃ©ro gestion d'infrastructure

### Contraintes
- âœ… DÃ©veloppeur solo (pas de DevOps)
- âœ… Provider franÃ§ais/europÃ©en
- âœ… Focus sur le produit, pas l'infra
- âœ… Calculs longs = problÃ¨me futur (si besoin)

---

## ğŸš€ SOLUTION RECOMMANDÃ‰E : Scaleway Serverless Containers

### Pourquoi Serverless Containers > Serverless Functions ?

| CritÃ¨re | Functions | Containers |
|---------|-----------|------------|
| **Limite nombre** | 1000 max | âˆ (illimitÃ©) |
| **DurÃ©e exÃ©cution** | 15min max | 10min par dÃ©faut |
| **FlexibilitÃ©** | Code ZIP only | Image Docker custom |
| **DÃ©pendances** | LimitÃ©es | Full control |
| **Cold start** | ~500ms | ~2-3s |
| **CoÃ»t idle** | â‚¬0 | â‚¬0 |
| **Gestion** | âš¡ Zero | âš¡ Minimal |

**âœ… Verdict : Serverless Containers = meilleur choix**

---

## ğŸ—ï¸ ARCHITECTURE PROPOSÃ‰E (100% Serverless)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UTILISATEUR                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FastAPI (Clever Cloud / Scaleway Containers)    â”‚
â”‚     - Auth Keycloak                                 â”‚
â”‚     - Routes CRUD tasks/workflows                   â”‚
â”‚     - Dispatch vers Serverless Containers           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL      â”‚   â”‚  Redis         â”‚
â”‚  (Scaleway DB)   â”‚   â”‚  (Scaleway)    â”‚
â”‚  - Metadata      â”‚   â”‚  - Job Queue   â”‚
â”‚  - Results refs  â”‚   â”‚  - Cache       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Serverless Containerâ”‚         â”‚ Object Storage     â”‚
â”‚ (Auto-scale 0-âˆ)    â”‚         â”‚ (Scaleway S3)      â”‚
â”‚ - ExÃ©cution calculs â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - Input files      â”‚
â”‚ - Python env custom â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º - Output results   â”‚
â”‚ - NumPy, SciPy, etc â”‚         â”‚ - Logs             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ COMPOSANTS DÃ‰TAILLÃ‰S

### **1. API FastAPI (Clever Cloud ou Scaleway Containers)**

**Option A : Clever Cloud** (recommandÃ© pour MVP)
```yaml
Type: Python app
RÃ©gion: Paris
Auto-scaling: 1-3 instances
CoÃ»t: ~â‚¬7-20/mois
```

**Option B : Scaleway Serverless Containers** (plus scalable)
```yaml
Type: Container
Image: registry.scaleway.com/mecapy/api:latest
Scaling: 0-10 instances
CoÃ»t: Pay-per-use (â‚¬0 si inactif)
```

**Endpoints** :
```python
POST /api/tasks              # CrÃ©er une tÃ¢che
POST /api/tasks/{id}/execute # ExÃ©cuter (dispatch to container)
GET  /api/tasks/{id}/status  # Polling status
GET  /api/tasks/{id}/results # RÃ©cupÃ©rer rÃ©sultats
```

---

### **2. Serverless Containers (workers de calcul)**

**Configuration** :
```dockerfile
# Dockerfile pour worker
FROM python:3.12-slim

# Installer dÃ©pendances scientifiques
RUN pip install numpy scipy pandas matplotlib

# Copier le code de la plateforme
COPY worker/ /app/
WORKDIR /app

# Endpoint HTTP pour recevoir les jobs
CMD ["uvicorn", "worker:app", "--host", "0.0.0.0", "--port", "8080"]
```

**DÃ©ploiement** :
```bash
# Build et push image
docker build -t mecapy-worker:v1 .
docker tag mecapy-worker:v1 registry.scaleway.com/mecapy/worker:v1
docker push registry.scaleway.com/mecapy/worker:v1

# CrÃ©er namespace serverless
scw container namespace create name=mecapy region=fr-par

# DÃ©ployer container
scw container container create \
  namespace-id=<namespace-id> \
  name=mecapy-worker \
  registry-image=registry.scaleway.com/mecapy/worker:v1 \
  min-scale=0 \
  max-scale=10 \
  memory-limit=2048 \
  cpu-limit=1000
```

**Code worker simplifiÃ©** :
```python
# worker.py
from fastapi import FastAPI
import boto3
import json

app = FastAPI()

@app.post("/execute")
async def execute_task(payload: dict):
    """
    ReÃ§oit un job de calcul depuis l'API.

    payload = {
        "task_id": "uuid",
        "code": "base64_encoded_python",
        "inputs_s3_key": "inputs/uuid.json",
        "user_id": "uuid"
    }
    """

    # 1. Download inputs from S3
    s3 = boto3.client('s3')
    inputs = s3.get_object(
        Bucket='mecapy-storage',
        Key=payload['inputs_s3_key']
    )

    # 2. Execute user code (sandboxed)
    result = execute_user_code(
        code=payload['code'],
        inputs=json.loads(inputs['Body'].read())
    )

    # 3. Upload results to S3
    s3.put_object(
        Bucket='mecapy-storage',
        Key=f"results/{payload['task_id']}.json",
        Body=json.dumps(result)
    )

    # 4. Return status
    return {"status": "completed", "result_key": f"results/{payload['task_id']}.json"}
```

**Limites Scaleway Serverless Containers** :
- âœ… **Nombre illimitÃ©** de containers (pas de limite 1000)
- âœ… **Auto-scaling** : 0 â†’ 10 instances automatiquement
- âš ï¸ **Timeout** : 10min par dÃ©faut (peut Ãªtre augmentÃ© Ã  15min)
- âš ï¸ **Cold start** : 2-3s (acceptable pour calculs longs)

---

### **3. Job Queue : Redis (Scaleway Managed)**

**Pourquoi Redis ?**
- âœ… GÃ©rer la file d'attente de tÃ¢ches
- âœ… Ã‰viter surcharge des containers
- âœ… Retry automatique en cas d'Ã©chec

**Configuration** :
```python
# api/services/queue.py
import redis
import json

class JobQueue:
    def __init__(self):
        self.redis = redis.from_url(os.getenv("REDIS_URL"))

    def enqueue(self, task_id: str, payload: dict):
        """Ajoute un job dans la queue"""
        self.redis.rpush("mecapy:jobs", json.dumps({
            "task_id": task_id,
            "payload": payload,
            "enqueued_at": datetime.utcnow().isoformat()
        }))

    def dequeue(self) -> dict | None:
        """RÃ©cupÃ¨re le prochain job"""
        job = self.redis.blpop("mecapy:jobs", timeout=5)
        return json.loads(job[1]) if job else None
```

**CoÃ»t** : ~â‚¬10/mois (Managed Redis Database 256MB)

---

### **4. Orchestration des tÃ¢ches**

**Flux d'exÃ©cution** :

```python
# api/routes/tasks.py
from fastapi import APIRouter, BackgroundTasks
import httpx

router = APIRouter()

@router.post("/tasks/{task_id}/execute")
async def execute_task(task_id: str, background_tasks: BackgroundTasks):
    """Lance l'exÃ©cution d'une tÃ¢che"""

    # 1. RÃ©cupÃ©rer mÃ©tadonnÃ©es
    task = await db.get_task(task_id)

    # 2. PrÃ©parer inputs dans S3
    s3_key = await upload_inputs_to_s3(task.inputs)

    # 3. Enqueue job
    await queue.enqueue(task_id, {
        "code": task.code,
        "inputs_s3_key": s3_key,
        "user_id": task.user_id
    })

    # 4. Lancer worker async (background)
    background_tasks.add_task(dispatch_to_worker, task_id)

    return {"status": "queued", "task_id": task_id}


async def dispatch_to_worker(task_id: str):
    """Dispatch job vers Serverless Container"""

    # RÃ©cupÃ©rer job de la queue
    job = await queue.dequeue()

    # Appeler Serverless Container
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://mecapy-worker-<namespace>.containers.fnc.fr-par.scw.cloud/execute",
            json=job["payload"],
            timeout=600.0  # 10min max
        )

    # Update task status
    await db.update_task_status(task_id, "completed", response.json())
```

---

## ğŸ”¥ GESTION DES CALCULS LONGS (> 10min)

### **StratÃ©gie progressive** :

#### **Phase 1 (MVP) : Jusqu'Ã  10min max**
âœ… Serverless Containers suffisent
âœ… Couvre 95% des cas d'usage initiaux

#### **Phase 2 (Si besoin > 10min) : Architecture hybride**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         API FastAPI                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ Router  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
    â–¼                     â–¼
Short tasks          Long tasks
(< 10min)            (> 10min)
    â”‚                     â”‚
    â–¼                     â–¼
Serverless          Dedicated VM
Container           (OVH GPU/CPU)
(Scaleway)          (lancÃ© on-demand)
```

**Option pour calculs longs** :
1. **Scaleway GPU Instances** (on-demand)
   - LancÃ©es uniquement pour calculs > 10min
   - DÃ©truite aprÃ¨s exÃ©cution
   - CoÃ»t : pay-per-use (~â‚¬0.50/h GPU)

2. **OVH Public Cloud Instances** (alternative)
   - Plus flexible pour calculs trÃ¨s longs
   - Support GPU/CPU haute performance

**Trigger automatique** :
```python
# api/services/task_router.py
def route_task(task: Task) -> ExecutionBackend:
    """Choisir le backend selon estimation"""

    estimated_duration = task.estimate_duration()

    if estimated_duration < 600:  # < 10min
        return "serverless_container"
    else:
        return "dedicated_instance"
```

---

## ğŸ’° COÃ›TS ESTIMÃ‰S (100% Serverless)

### **Phase 1 : MVP (0-1000 calculs/jour)**

| Service | Type | CoÃ»t mensuel |
|---------|------|--------------|
| **FastAPI** | Clever Cloud (Nano) | â‚¬7-10/mois |
| **PostgreSQL** | Scaleway DB 1GB | â‚¬18/mois |
| **Redis** | Scaleway DB 256MB | â‚¬10/mois |
| **Object Storage** | Scaleway S3 (10GB) | â‚¬0.20/mois |
| **Serverless Containers** | Pay-per-use (100h/mois) | â‚¬5-15/mois |
| **Registry** | Scaleway Container Registry | Gratuit (100GB) |
| **Total** | | **~â‚¬40-55/mois** |

**Calculs serverless** :
- â‚¬0.00001/GB-s (mÃ©moire)
- â‚¬0.000012/vCPU-s
- Exemple : 1000 calculs Ã— 30s Ã— 2GB = ~â‚¬6/mois

### **Phase 2 : Scale (1000-10 000 calculs/jour)**

| Service | CoÃ»t mensuel |
|---------|--------------|
| Base (API + DB + Redis) | â‚¬35/mois |
| Serverless Containers (1000h/mois) | â‚¬50-80/mois |
| Object Storage (100GB) | â‚¬2/mois |
| **Total** | **~â‚¬90-120/mois** |

---

## âš¡ AVANTAGES DE CETTE ARCHITECTURE

### âœ… **Pour le dÃ©veloppeur solo**
1. **ZÃ©ro gestion d'infra** : Pas de K8s, pas de VMs Ã  maintenir
2. **Scaling automatique** : 0 â†’ 10 containers selon charge
3. **CoÃ»t variable** : Paye uniquement l'usage rÃ©el
4. **DÃ©ploiement simple** : `docker push` + config Scaleway
5. **Monitoring inclus** : Dashboard Scaleway native

### âœ… **Pour les utilisateurs**
1. **Latence acceptable** : 2-3s cold start (nÃ©gligeable si calcul > 10s)
2. **FiabilitÃ©** : Infrastructure managÃ©e Scaleway
3. **Scaling transparent** : 100 ou 10 000 calculs, mÃªme architecture

### âœ… **Pour l'Ã©volution**
1. **Phase 1** : 100% serverless (simple)
2. **Phase 2** : Ajouter VMs on-demand pour calculs longs (si besoin)
3. **Phase 3** : Migration K8s uniquement si > 50 000 calculs/jour

---

## ğŸš€ PLAN DE DÃ‰PLOIEMENT (QUICK START)

### **Semaine 1 : Infrastructure**
```bash
# 1. CrÃ©er compte Scaleway
scw init

# 2. Provisionner services
scw rdb instance create \
  name=mecapy-postgres \
  engine=postgresql-15 \
  node-type=db-dev-s

scw redis cluster create \
  name=mecapy-redis \
  node-type=RED1-micro

# 3. CrÃ©er bucket S3
scw object bucket create \
  name=mecapy-storage \
  region=fr-par
```

### **Semaine 2 : API + Worker**
```bash
# 1. DÃ©ployer API sur Clever Cloud
clever create --type python mecapy-api
clever deploy

# 2. Build worker image
docker build -t mecapy-worker:v1 ./worker
docker push registry.scaleway.com/mecapy/worker:v1

# 3. DÃ©ployer Serverless Container
scw container container deploy \
  --name mecapy-worker \
  --registry-image mecapy/worker:v1
```

### **Semaine 3 : Tests + Production**
```bash
# Test end-to-end
curl -X POST https://api.mecapy.com/tasks/execute \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"code": "...", "inputs": {...}}'

# Monitoring
scw container container logs mecapy-worker
```

---

## ğŸ¯ WORKFLOW UTILISATEUR SIMPLIFIÃ‰

### **1. CrÃ©er une tÃ¢che**
```python
# SDK Python
from mecapy import MecaPy

client = MecaPy(token="xxx")

task = client.tasks.create(
    name="Calcul contrainte vis",
    code="""
def calculate(inputs):
    import numpy as np
    force = inputs['force']
    section = inputs['section']
    return {'stress': force / section}
""",
    inputs={"force": 1000, "section": 10}
)
```

### **2. ExÃ©cuter**
```python
result = task.execute()  # Bloquant
# OU
task.execute_async()     # Non-bloquant
```

### **3. RÃ©cupÃ©rer rÃ©sultats**
```python
if task.status == "completed":
    print(task.result)  # {'stress': 100}
```

---

## ğŸ”’ SÃ‰CURITÃ‰ (Serverless)

### **Isolation**
```python
# worker/sandbox.py
import RestrictedPython
from RestrictedPython import safe_builtins

def execute_user_code(code: str, inputs: dict) -> dict:
    """ExÃ©cute le code utilisateur en sandbox"""

    # 1. Compiler code en mode restreint
    byte_code = RestrictedPython.compile_restricted(
        code,
        filename='<user_code>',
        mode='exec'
    )

    # 2. Whitelist imports
    safe_globals = {
        '__builtins__': safe_builtins,
        'numpy': __import__('numpy'),
        'scipy': __import__('scipy'),
        'pandas': __import__('pandas'),
    }

    # 3. ExÃ©cuter avec timeout
    exec(byte_code, safe_globals)

    # 4. Appeler fonction calculate()
    return safe_globals['calculate'](inputs)
```

---

## ğŸ“Š COMPARAISON FINALE

| CritÃ¨re | Serverless Containers | K8s + Celery | Serverless Functions |
|---------|----------------------|--------------|---------------------|
| **Gestion infra** | âš¡ ZÃ©ro | ğŸ”´ Ã‰levÃ©e | âš¡ ZÃ©ro |
| **ComplexitÃ©** | ğŸŸ¢ Simple | ğŸ”´ Complexe | ğŸŸ¢ Simple |
| **Limite nombre** | âœ… IllimitÃ© | âœ… IllimitÃ© | âŒ 1000 |
| **Timeout** | âš ï¸ 10min | âœ… IllimitÃ© | âš ï¸ 15min |
| **CoÃ»t base** | â‚¬0 | â‚¬50/mois | â‚¬0 |
| **CoÃ»t scale** | â‚¬â‚¬ | â‚¬â‚¬ | â‚¬â‚¬â‚¬ |
| **FlexibilitÃ©** | âœ… Docker | âœ… Total | âŒ ZIP only |
| **RecommandÃ© solo** | âœ…âœ…âœ… | âŒ | âš ï¸ |

---

## âœ… RECOMMANDATION FINALE

### **ğŸ¯ Pour dÃ©marrer (0-6 mois)**
â†’ **100% Serverless Containers Scaleway**
- CoÃ»t : ~â‚¬50/mois
- Maintenance : ~1h/mois
- Focus : DÃ©veloppement produit

### **ğŸš€ Si besoin calculs > 10min**
â†’ **Ajouter instances on-demand** (Scaleway GPU/CPU)
- LancÃ©es automatiquement si `estimated_duration > 10min`
- DÃ©truites aprÃ¨s exÃ©cution
- CoÃ»t additionnel : ~â‚¬20-50/mois

### **ğŸ“ˆ Si > 50 000 calculs/jour**
â†’ **Migrer vers K8s + Celery**
- Seulement si rentable Ã©conomiquement
- Probablement dans 1-2 ans

---

**âœ… Verdict : Serverless Containers = Architecture idÃ©ale pour dÃ©veloppeur solo**

**Document gÃ©nÃ©rÃ© le** : 2025-09-30
**Version** : 2.0 - Architecture Serverless
