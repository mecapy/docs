# EXÃ‰CUTION SÃ‰CURISÃ‰E DU CODE UTILISATEUR - ANALYSE APPROFONDIE

## ðŸŽ¯ PROBLÃ‰MATIQUE

### DÃ©fis Ã  rÃ©soudre
1. **SÃ©curitÃ©** : EmpÃªcher code malveillant (accÃ¨s filesystem, rÃ©seau, fork bomb, etc.)
2. **Isolation** : Chaque calcul ne doit pas affecter les autres
3. **DÃ©pendances** : Worker ne doit PAS avoir les dÃ©pendances utilisateur installÃ©es
4. **Performance** : Overhead minimal pour calculs courts
5. **Ressources** : Limiter CPU/RAM/temps par calcul

---

## ðŸ—ï¸ SOLUTIONS POSSIBLES (5 approches)

### **Approche 1 : Docker-in-Docker (DinD)** â­ RECOMMANDÃ‰

**Concept** : Le worker lance un conteneur Docker temporaire pour chaque calcul

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Container (Serverless/VM)       â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Worker Process (Python)          â”‚ â”‚
â”‚  â”‚  - Poll Redis                     â”‚ â”‚
â”‚  â”‚  - Download code from S3          â”‚ â”‚
â”‚  â”‚  - Launch Docker container â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”
â”‚  â”‚  - Wait for completion            â”‚ â”‚  â”‚
â”‚  â”‚  - Upload results to S3           â”‚ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                                         â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
        â”‚  Execution Container (Ã©phÃ©mÃ¨re)          â”‚
        â”‚  - Image custom utilisateur              â”‚
        â”‚  - DÃ©pendances: numpy, scipy, Code_Aster â”‚
        â”‚  - CPU limit: 2 cores                    â”‚
        â”‚  - Memory limit: 4GB                     â”‚
        â”‚  - Network: disabled                     â”‚
        â”‚  - Filesystem: read-only sauf /tmp       â”‚
        â”‚  - Timeout: 5min                         â”‚
        â”‚                                           â”‚
        â”‚  $ python /tmp/user_code.py              â”‚
        â”‚  â†’ Execute code                          â”‚
        â”‚  â†’ Write output.json                     â”‚
        â”‚  â†’ Container destroyed                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Code Worker avec Docker-in-Docker**

```python
# worker/docker_executor.py
import docker
import json
import tempfile
import time
from pathlib import Path

class DockerExecutor:
    """Execute user code in isolated Docker containers"""

    def __init__(self):
        self.docker_client = docker.from_env()

    def execute(self, task: dict) -> dict:
        """
        Execute user code in isolated container.

        task = {
            "task_id": "uuid",
            "code": "def calculate(inputs): ...",
            "inputs": {"param1": 10},
            "runtime": "python:3.12",  # ou custom image
            "requirements": ["numpy==1.24.0", "scipy==1.10.0"],
            "timeout": 300,
            "memory_limit": "2g",
            "cpu_limit": 2.0
        }
        """

        task_id = task['task_id']

        # 1. CrÃ©er rÃ©pertoire temporaire pour le code
        with tempfile.TemporaryDirectory() as tmpdir:
            tmpdir_path = Path(tmpdir)

            # 2. Ã‰crire le code utilisateur
            code_file = tmpdir_path / "user_code.py"
            code_file.write_text(self._wrap_user_code(task['code']))

            # 3. Ã‰crire les inputs
            inputs_file = tmpdir_path / "inputs.json"
            inputs_file.write_text(json.dumps(task['inputs']))

            # 4. CrÃ©er requirements.txt si besoin
            if task.get('requirements'):
                req_file = tmpdir_path / "requirements.txt"
                req_file.write_text('\n'.join(task['requirements']))

            # 5. Lancer container Docker avec restrictions
            try:
                container = self.docker_client.containers.run(
                    image=task.get('runtime', 'python:3.12-slim'),
                    command=self._get_execution_command(task),

                    # Volumes: mount code en read-only
                    volumes={
                        str(tmpdir_path): {
                            'bind': '/workspace',
                            'mode': 'ro'  # Read-only !
                        }
                    },

                    # Limits de ressources
                    mem_limit=task.get('memory_limit', '2g'),
                    cpu_quota=int(task.get('cpu_limit', 2.0) * 100000),
                    cpu_period=100000,

                    # SÃ©curitÃ©
                    network_mode='none',  # Pas d'accÃ¨s rÃ©seau !
                    read_only=True,       # Filesystem read-only
                    security_opt=['no-new-privileges'],
                    cap_drop=['ALL'],     # Drop toutes les capabilities

                    # Tmpfs pour /tmp (RAM disk)
                    tmpfs={'/tmp': 'size=512m,mode=1777'},

                    # Timeout
                    detach=True,
                    remove=False  # On nettoie manuellement aprÃ¨s
                )

                # 6. Attendre la fin (avec timeout)
                result = container.wait(timeout=task.get('timeout', 300))

                # 7. RÃ©cupÃ©rer les logs (stdout/stderr)
                logs = container.logs(stdout=True, stderr=True).decode()

                # 8. RÃ©cupÃ©rer output.json depuis le container
                output_data = self._extract_output(container, '/tmp/output.json')

                # 9. Nettoyer le container
                container.remove(force=True)

                # 10. Retourner rÃ©sultat
                return {
                    'status': 'success' if result['StatusCode'] == 0 else 'error',
                    'output': output_data,
                    'logs': logs,
                    'exit_code': result['StatusCode']
                }

            except docker.errors.ContainerError as e:
                return {
                    'status': 'error',
                    'error': f"Container error: {str(e)}",
                    'logs': e.stderr.decode() if e.stderr else ''
                }

            except Exception as e:
                return {
                    'status': 'error',
                    'error': str(e)
                }

    def _wrap_user_code(self, user_code: str) -> str:
        """Wrap user code with safety harness"""

        wrapper = f'''
import json
import sys
import signal

# Timeout handler
def timeout_handler(signum, frame):
    raise TimeoutError("Execution timeout")

signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(300)  # 5min max

try:
    # Load inputs
    with open('/workspace/inputs.json', 'r') as f:
        inputs = json.load(f)

    # User code
{self._indent_code(user_code, 4)}

    # Execute calculate function
    result = calculate(inputs)

    # Write output
    with open('/tmp/output.json', 'w') as f:
        json.dump(result, f)

    sys.exit(0)

except Exception as e:
    error_output = {{"error": str(e), "type": type(e).__name__}}
    with open('/tmp/output.json', 'w') as f:
        json.dump(error_output, f)
    sys.exit(1)
'''
        return wrapper

    def _indent_code(self, code: str, spaces: int) -> str:
        """Indent user code"""
        indent = ' ' * spaces
        return '\n'.join(indent + line for line in code.split('\n'))

    def _get_execution_command(self, task: dict) -> list:
        """Get Docker command to execute"""

        commands = []

        # Install requirements if specified
        if task.get('requirements'):
            commands.append('pip install --no-cache-dir -r /workspace/requirements.txt')

        # Execute user code
        commands.append('python /workspace/user_code.py')

        return ['sh', '-c', ' && '.join(commands)]

    def _extract_output(self, container, file_path: str) -> dict:
        """Extract output file from container"""
        try:
            bits, stat = container.get_archive(file_path)

            # Extract tar archive
            import tarfile
            import io

            tar_stream = io.BytesIO(b''.join(bits))
            tar = tarfile.open(fileobj=tar_stream)

            # Read output.json
            output_file = tar.extractfile('output.json')
            return json.loads(output_file.read().decode())

        except Exception as e:
            return {'error': f'Failed to extract output: {str(e)}'}
```

#### **Avantages Docker-in-Docker**
- âœ… **Isolation parfaite** : Kernel namespaces + cgroups
- âœ… **DÃ©pendances custom** : Chaque user peut avoir son image
- âœ… **Limits strictes** : CPU, RAM, rÃ©seau, filesystem
- âœ… **Nettoyage automatique** : Container dÃ©truit aprÃ¨s
- âœ… **SÃ©curitÃ© prouvÃ©e** : Technologie mature

#### **InconvÃ©nients**
- âš ï¸ **Overhead** : ~2-5s pour spawn container (acceptable si calcul > 10s)
- âš ï¸ **ComplexitÃ©** : Besoin de Docker daemon sur le worker
- âš ï¸ **Ressources** : ~200MB RAM par container

---

### **Approche 2 : gVisor (runsc)** â­â­ TRÃˆS SÃ‰CURISÃ‰

**Concept** : Sandbox ultra-sÃ©curisÃ© avec syscall interception

gVisor = Runtime container de Google qui intercepte TOUS les syscalls

```python
# worker/gvisor_executor.py
import subprocess
import json

class GVisorExecutor:
    """Execute code with gVisor sandbox"""

    def execute(self, task: dict) -> dict:
        # 1. CrÃ©er OCI bundle (config.json + rootfs)
        bundle_path = self._create_oci_bundle(task)

        # 2. Lancer avec runsc (gVisor runtime)
        result = subprocess.run(
            [
                'runsc',
                '--network=none',
                '--platform=ptrace',  # ou kvm pour meilleures perfs
                'run',
                '--bundle', bundle_path,
                task['task_id']
            ],
            capture_output=True,
            timeout=task.get('timeout', 300)
        )

        # 3. RÃ©cupÃ©rer rÃ©sultat
        return self._parse_output(result)
```

**Avantages gVisor** :
- âœ… **SÃ©curitÃ© maximale** : Syscall interception
- âœ… **Pas besoin VM** : Plus lÃ©ger que VMs
- âœ… **Compatible Docker** : Drop-in replacement

**InconvÃ©nients** :
- âš ï¸ **Overhead** : 10-20% plus lent que Docker natif
- âš ï¸ **ComplexitÃ© setup** : Installer gVisor sur workers

---

### **Approche 3 : Firecracker MicroVMs** â­â­â­ ULTRA RAPIDE

**Concept** : MicroVMs ultra-lÃ©gÃ¨res (AWS Lambda utilise Ã§a)

```
Worker lance une MicroVM Firecracker par calcul
â†’ Boot en 125ms
â†’ Isolation kernel complÃ¨te
â†’ Destroy aprÃ¨s exÃ©cution
```

```python
# worker/firecracker_executor.py
import requests
import json

class FirecrackerExecutor:
    """Execute code in Firecracker microVM"""

    def __init__(self):
        self.firecracker_socket = '/tmp/firecracker.sock'

    def execute(self, task: dict) -> dict:
        # 1. Configure microVM
        self._configure_vm(
            vcpu_count=task.get('cpu_limit', 2),
            mem_size_mib=task.get('memory_mb', 2048),
            kernel_image='/path/to/vmlinux',
            rootfs='/path/to/rootfs.ext4'
        )

        # 2. Boot microVM (125ms)
        self._boot_vm()

        # 3. Execute code via vsock
        result = self._execute_in_vm(task['code'], task['inputs'])

        # 4. Shutdown VM
        self._shutdown_vm()

        return result

    def _configure_vm(self, **config):
        """Configure Firecracker via API"""
        requests.put(
            f'http://localhost/machine-config',
            json={
                'vcpu_count': config['vcpu_count'],
                'mem_size_mib': config['mem_size_mib']
            }
        )
```

**Avantages Firecracker** :
- âœ… **Boot ultra-rapide** : 125ms (vs 2-5s Docker)
- âœ… **Isolation kernel complÃ¨te** : Vraie VM
- âœ… **LÃ©ger** : 5MB RAM overhead
- âœ… **Production-proven** : AWS Lambda, Fly.io

**InconvÃ©nients** :
- ðŸ”´ **ComplexitÃ© Ã©levÃ©e** : Setup non-trivial
- ðŸ”´ **Linux only** : NÃ©cessite KVM
- ðŸŸ¡ **Pas de support Windows/Mac**

---

### **Approche 4 : RestrictedPython** âš ï¸ DÃ‰CONSEILLÃ‰ SEUL

**Concept** : Sandbox Python natif (pas de conteneur)

```python
# worker/restricted_executor.py
from RestrictedPython import compile_restricted, safe_builtins
import RestrictedPython.Guards

def execute_user_code(code: str, inputs: dict) -> dict:
    """Execute in Python sandbox (NOT SECURE ENOUGH ALONE)"""

    # Compile code en mode restreint
    byte_code = compile_restricted(
        code,
        filename='<user_code>',
        mode='exec'
    )

    # Whitelist imports
    safe_globals = {
        '__builtins__': safe_builtins,
        '__name__': 'user_module',
        '__metaclass__': type,
        '_getattr_': RestrictedPython.Guards.safe_getattr,

        # Modules autorisÃ©s
        'numpy': __import__('numpy'),
        'scipy': __import__('scipy'),
        'math': __import__('math'),
    }

    # Execute
    exec(byte_code, safe_globals)

    # Call calculate()
    return safe_globals['calculate'](inputs)
```

**Avantages** :
- âœ… **TrÃ¨s rapide** : Pas d'overhead
- âœ… **Simple** : Pas de Docker/VM

**InconvÃ©nients** :
- ðŸ”´ **INSUFFISANT SEUL** : Bypasses possibles
- ðŸ”´ **Pas de limite CPU/RAM** : Doit Ãªtre combinÃ©
- ðŸ”´ **Imports limitÃ©s** : Difficile de whitelister tout

**â†’ Peut Ãªtre utilisÃ© EN COMBINAISON avec Docker** pour double protection

---

### **Approche 5 : Subprocess avec ulimit** âš ï¸ FAIBLE ISOLATION

```python
# worker/subprocess_executor.py
import subprocess
import resource

def execute_user_code(code: str, inputs: dict) -> dict:
    """Execute in subprocess with resource limits (WEAK)"""

    def set_limits():
        # Limite CPU: 5min
        resource.setrlimit(resource.RLIMIT_CPU, (300, 300))

        # Limite mÃ©moire: 2GB
        resource.setrlimit(resource.RLIMIT_AS, (2*1024*1024*1024, 2*1024*1024*1024))

        # Limite processus
        resource.setrlimit(resource.RLIMIT_NPROC, (1, 1))

    result = subprocess.run(
        ['python', '-c', code],
        input=json.dumps(inputs),
        capture_output=True,
        timeout=300,
        preexec_fn=set_limits  # Linux only
    )

    return json.loads(result.stdout)
```

**â†’ NE PAS UTILISER en production** : Isolation insuffisante

---

## ðŸ“Š COMPARAISON DES APPROCHES

| Approche | SÃ©curitÃ© | Performance | ComplexitÃ© | Isolation deps | CoÃ»t dev |
|----------|----------|-------------|------------|----------------|----------|
| **Docker-in-Docker** | â­â­â­â­ | ðŸŸ¡ (2-5s overhead) | ðŸŸ¢ Moyenne | âœ… Parfaite | ðŸŸ¢ 1 semaine |
| **gVisor** | â­â­â­â­â­ | ðŸŸ¡ (10-20% slower) | ðŸŸ¡ Moyenne | âœ… Parfaite | ðŸŸ¡ 2 semaines |
| **Firecracker** | â­â­â­â­â­ | âœ… (125ms boot) | ðŸ”´ Ã‰levÃ©e | âœ… Parfaite | ðŸ”´ 1 mois |
| **RestrictedPython** | â­â­ | âœ… (natif) | ðŸŸ¢ Simple | âŒ PartagÃ©e | ðŸŸ¢ 3 jours |
| **Subprocess** | â­ | âœ… (natif) | ðŸŸ¢ Simple | âŒ PartagÃ©e | ðŸŸ¢ 1 jour |

---

## ðŸŽ¯ RECOMMANDATION FINALE

### **Pour dÃ©marrer (MVP) : Docker-in-Docker** âœ…

**Pourquoi** :
1. âœ… **Bon compromis** sÃ©curitÃ©/performance/complexitÃ©
2. âœ… **Isolation parfaite** des dÃ©pendances
3. âœ… **Technologie mature** : Docker = production-proven
4. âœ… **Facile Ã  debugger** : `docker logs`, `docker inspect`
5. âœ… **Ã‰volutif** : Peut migrer vers Firecracker plus tard

**Setup Worker avec Docker** :

```dockerfile
# Dockerfile du Worker
FROM python:3.12-slim

# Installer Docker CLI
RUN apt-get update && apt-get install -y \
    docker.io \
    && rm -rf /var/lib/apt/lists/*

# Installer dÃ©pendances worker
RUN pip install redis boto3 docker

COPY worker/ /app/
WORKDIR /app

CMD ["python", "worker.py"]
```

**DÃ©ploiement** :
```bash
# Sur Scaleway Serverless Containers
scw container container create \
  --name mecapy-worker \
  --privileged true \  # NÃ©cessaire pour Docker-in-Docker
  --registry-image mecapy/worker:v1

# OU sur VMs
docker run -d \
  -v /var/run/docker.sock:/var/run/docker.sock \  # Socket Docker
  mecapy-worker:v1
```

---

## ðŸ”¥ ARCHITECTURE RECOMMANDÃ‰E FINALE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API FastAPI (Clever Cloud)                           â”‚
â”‚  - Enqueue job dans Redis                             â”‚
â”‚  - Upload code/inputs vers S3                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Queue     â”‚       â”‚  PostgreSQL     â”‚
â”‚  - mecapy:jobs   â”‚       â”‚  - Tasks meta   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WORKER POOL (5 Serverless Containers ou VMs)        â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Worker Process                              â”‚    â”‚
â”‚  â”‚ 1. Poll Redis (blpop)                       â”‚    â”‚
â”‚  â”‚ 2. Download code/inputs from S3             â”‚    â”‚
â”‚  â”‚ 3. Launch Docker container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”
â”‚  â”‚ 4. Wait completion                          â”‚    â”‚  â”‚
â”‚  â”‚ 5. Upload result to S3                      â”‚    â”‚  â”‚
â”‚  â”‚ 6. Update Redis/PostgreSQL                  â”‚    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  EXECUTION CONTAINER (Ã©phÃ©mÃ¨re, dÃ©truit aprÃ¨s)            â”‚
        â”‚                                                            â”‚
        â”‚  Image: python:3.12 (ou custom avec numpy/scipy)          â”‚
        â”‚  Limits:                                                   â”‚
        â”‚    - CPU: 2 cores                                          â”‚
        â”‚    - RAM: 4GB                                              â”‚
        â”‚    - Network: DISABLED                                     â”‚
        â”‚    - Filesystem: READ-ONLY (sauf /tmp)                     â”‚
        â”‚    - Timeout: 5min                                         â”‚
        â”‚                                                            â”‚
        â”‚  Security:                                                 â”‚
        â”‚    - no-new-privileges                                     â”‚
        â”‚    - cap-drop=ALL                                          â”‚
        â”‚    - User: non-root                                        â”‚
        â”‚                                                            â”‚
        â”‚  Execution:                                                â”‚
        â”‚    $ pip install -r requirements.txt  # si nÃ©cessaire      â”‚
        â”‚    $ python /workspace/user_code.py                        â”‚
        â”‚    â†’ Write /tmp/output.json                                â”‚
        â”‚    â†’ Container destroyed                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”’ SÃ‰CURITÃ‰ MULTICOUCHE

### **Couche 1 : Validation API**
```python
# api/validation.py
def validate_user_code(code: str) -> bool:
    """Validation statique du code"""

    # Blacklist imports dangereux
    forbidden = ['os', 'subprocess', 'sys', 'socket', '__import__']
    for module in forbidden:
        if f'import {module}' in code:
            raise SecurityError(f"Forbidden module: {module}")

    # Taille max code
    if len(code) > 100_000:  # 100KB
        raise ValueError("Code too large")

    return True
```

### **Couche 2 : RestrictedPython (optionnel, dÃ©fense en profondeur)**
```python
# worker/restricted_wrapper.py
from RestrictedPython import compile_restricted

def wrap_code(user_code: str) -> str:
    """Double validation avec RestrictedPython"""

    # Tenter compilation restreinte
    compile_restricted(user_code, '<string>', 'exec')

    # Si OK, retourner code wrapped
    return user_code
```

### **Couche 3 : Docker isolation (principal)**
- Network disabled
- Filesystem read-only
- Capabilities dropped
- Cgroups limits

### **Couche 4 : Monitoring**
```python
# worker/monitor.py
def monitor_execution(container):
    """Monitor container pour dÃ©tection anomalies"""

    stats = container.stats(stream=False)

    # Check CPU spike
    if stats['cpu_stats']['cpu_usage']['total_usage'] > THRESHOLD:
        container.kill()

    # Check memory
    if stats['memory_stats']['usage'] > MEMORY_LIMIT:
        container.kill()
```

---

## ðŸ’° COÃ›TS OVERHEAD DOCKER

### **Par calcul** :
- Spawn container : 2-5s
- Execution : Variable (10s-5min)
- Destroy : 0.5s
- **Total overhead : 2.5-6s**

**â†’ Acceptable si calcul > 10s** (overhead < 30%)

### **Optimisation possible** :
```python
# Pool de containers prÃ©-crÃ©Ã©s (optionnel)
class ContainerPool:
    def __init__(self, size=3):
        self.pool = [
            docker_client.containers.create('python:3.12')
            for _ in range(size)
        ]

    def get_container(self):
        """RÃ©utiliser container au lieu de crÃ©er"""
        container = self.pool.pop()
        container.restart()
        return container
```

**â†’ RÃ©duit overhead Ã  ~500ms** mais complexitÃ© accrue

---

## âœ… PLAN D'IMPLÃ‰MENTATION

### **Semaine 1 : Proof of Concept**
```bash
# Test Docker executor localement
python test_docker_executor.py

# VÃ©rifier isolation
- Code malveillant bloquÃ© ?
- Limits CPU/RAM respectÃ©es ?
- Timeout fonctionne ?
```

### **Semaine 2 : IntÃ©gration Worker**
```python
# worker/worker.py
from docker_executor import DockerExecutor

executor = DockerExecutor()

while True:
    job = redis.blpop('mecapy:jobs')
    result = executor.execute(job)
    upload_to_s3(result)
```

### **Semaine 3 : Tests de charge**
```bash
# 100 calculs simultanÃ©s
python benchmark.py --concurrent 100
```

### **Semaine 4 : Production**
```bash
# Deploy 5 workers
./deploy_workers.sh 5
```

---

## ðŸ“‹ ALTERNATIVE SI DOCKER-IN-DOCKER IMPOSSIBLE

### **Option : Workers dÃ©diÃ©s par runtime**

```
Worker Pool A (3 workers) : Python + NumPy/SciPy
Worker Pool B (2 workers) : Python + Code_Aster
Worker Pool C (2 workers) : Python + Custom deps

â†’ API route selon requirements
```

**Avantages** :
- âœ… Pas besoin Docker-in-Docker
- âœ… DÃ©pendances prÃ©-installÃ©es (plus rapide)

**InconvÃ©nients** :
- âŒ Moins flexible (limitÃ© aux runtimes prÃ©dÃ©finis)
- âŒ Maintenance de plusieurs images

---

**âœ… VERDICT : Docker-in-Docker = Meilleur compromis pour MVP**

**Document gÃ©nÃ©rÃ© le** : 2025-09-30
**Version** : 1.0 - Analyse exÃ©cution sÃ©curisÃ©e
